This project involves developing solutions which would allow the content of live talks to be streamed in textual format to deaf participants at the venue (in or near real time).

This system would utilise automatic speech recognition (ASR) technology to “translate” the speakers voice into text which could then be streamed to a custom app or web page based application.

A number of deployment models should be considered.

An “infrastructural” model where the speaker’s PC is responsible for the ASR functionality and the resultant text is then accessed through a web page

OR

A more flexible “single user” model where perhaps a mobile app completes the ASR functionality and transmit the text over WiFi or Bluetooth to a custom app on a single user’s PC.

This form of technology would be suitable for use by both deaf and hearing impaired individuals but also individuals with limited limb mobility as a note taking tool.